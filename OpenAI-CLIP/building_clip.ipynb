{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-09-11T10:12:52.636100Z","iopub.status.busy":"2023-09-11T10:12:52.635566Z","iopub.status.idle":"2023-09-11T10:13:09.320115Z","shell.execute_reply":"2023-09-11T10:13:09.318571Z","shell.execute_reply.started":"2023-09-11T10:12:52.636062Z"},"trusted":true},"outputs":[],"source":["!pip install git+https://github.com/openai/CLIP.git -q"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-09-11T10:13:09.322630Z","iopub.status.busy":"2023-09-11T10:13:09.322124Z","iopub.status.idle":"2023-09-11T10:13:11.605183Z","shell.execute_reply":"2023-09-11T10:13:11.603770Z","shell.execute_reply.started":"2023-09-11T10:13:09.322583Z"},"trusted":true},"outputs":[],"source":["import clip\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","from collections import OrderedDict"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-09-11T10:13:11.608118Z","iopub.status.busy":"2023-09-11T10:13:11.607179Z","iopub.status.idle":"2023-09-11T10:13:11.614618Z","shell.execute_reply":"2023-09-11T10:13:11.613415Z","shell.execute_reply.started":"2023-09-11T10:13:11.608073Z"},"trusted":true},"outputs":[],"source":["config = {\n","    'img_size': 224,\n","    'patch_size': 32,\n","    'vis_num_heads': 12,\n","    'vis_depth': 12,\n","    'vis_dim': 768,\n","    'vis_out_dim': 512,\n","    'mlp_ratio': 4,\n","    'qkv_bias': True,\n","    'vocab_size': 49408,\n","    'context_length': 77,\n","    'text_dim': 512,\n","    'text_depth': 12\n","}"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-09-11T10:13:11.619840Z","iopub.status.busy":"2023-09-11T10:13:11.619064Z","iopub.status.idle":"2023-09-11T10:13:11.632432Z","shell.execute_reply":"2023-09-11T10:13:11.631576Z","shell.execute_reply.started":"2023-09-11T10:13:11.619795Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['RN50',\n"," 'RN101',\n"," 'RN50x4',\n"," 'RN50x16',\n"," 'RN50x64',\n"," 'ViT-B/32',\n"," 'ViT-B/16',\n"," 'ViT-L/14',\n"," 'ViT-L/14@336px']"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["clip.available_models()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-09-11T10:13:11.633853Z","iopub.status.busy":"2023-09-11T10:13:11.633483Z","iopub.status.idle":"2023-09-11T10:13:16.944881Z","shell.execute_reply":"2023-09-11T10:13:16.943797Z","shell.execute_reply.started":"2023-09-11T10:13:11.633820Z"},"trusted":true},"outputs":[],"source":["model,_ = clip.load('ViT-B/32',download_root='/kaggle/working/')"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-09-11T10:13:16.946860Z","iopub.status.busy":"2023-09-11T10:13:16.946422Z","iopub.status.idle":"2023-09-11T10:13:16.962595Z","shell.execute_reply":"2023-09-11T10:13:16.960983Z","shell.execute_reply.started":"2023-09-11T10:13:16.946820Z"},"trusted":true},"outputs":[],"source":["class MultiheadAttention(nn.Module):\n","    def __init__(\n","        self,\n","        dim,\n","        num_heads\n","    ):\n","        super().__init__()\n","        \n","        assert dim % num_heads == 0\n","        self.dim = dim\n","        self.num_heads = num_heads\n","        self.head_dim = self.dim // self.num_heads\n","        self.scale = self.head_dim ** -0.5\n","        self.in_proj = nn.Linear(dim,dim*3)\n","        self.out_proj = nn.Linear(dim,dim)\n","        \n","    def forward(self,x, mask=None):\n","        # x: batch x seq x dim\n","        B,S,D = x.shape\n","        q, k, v = self.in_proj(x).chunk(3,dim=-1) # q,k,v: batch x seq x dim\n","        # to reshape into: batch x num_heads x seq x head_size\n","        q = q.view(B, S, self.num_heads, self.head_dim).permute(0,2,1,3)\n","        k = k.view(B, S, self.num_heads, self.head_dim).permute(0,2,1,3)\n","        v = v.view(B, S, self.num_heads, self.head_dim).permute(0,2,1,3)\n","        \n","        # k.T: batch x num_heads x head_size x seq\n","        # attn: batch x num_heads x seq x seq\n","        attn = (q @ k.transpose(-1,-2)) * self.scale\n","        \n","        if mask is not None:\n","            attn = attn.masked_fill(mask==0,float('-inf'))\n","            attn = F.softmax(attn,dim=-1)\n","        \n","        # attn: batch x num_heads x seq x head_size\n","        attn = attn @ v\n","        # attn: batch x seq x (num_heads x head_size=dim)\n","        attn = attn.permute(0,2,1,3).contiguous().view(B,S,D)\n","        out = self.out_proj(attn)\n","        return out"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-09-11T10:13:16.964721Z","iopub.status.busy":"2023-09-11T10:13:16.964205Z","iopub.status.idle":"2023-09-11T10:13:16.985741Z","shell.execute_reply":"2023-09-11T10:13:16.984751Z","shell.execute_reply.started":"2023-09-11T10:13:16.964678Z"},"trusted":true},"outputs":[],"source":["class ResidualAttentionBlock(nn.Module):\n","    def __init__(\n","        self,\n","        dim,\n","        num_heads,\n","        mask=None\n","    ):\n","        super().__init__()\n","        \n","        self.mask = mask\n","        self.attn = MultiheadAttention(\n","            dim = dim,\n","            num_heads = num_heads\n","        )\n","        \n","        self.ln_1 = nn.LayerNorm(dim)\n","        self.mlp = nn.Sequential(OrderedDict([\n","            ('c_fc',nn.Linear(dim,dim * 4)), # 4 : mlp ratio\n","            ('gelu',nn.GELU()),\n","            ('c_proj',nn.Linear(dim * 4,dim))\n","        ]))\n","        self.ln_2 = nn.LayerNorm(dim)\n","        \n","    def forward(self,x):\n","        x = x + self.attn(self.ln_1(x),mask=self.mask)\n","        x = x + self.mlp(self.ln_2(x))\n","        \n","        return x"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-09-11T10:13:16.988341Z","iopub.status.busy":"2023-09-11T10:13:16.987190Z","iopub.status.idle":"2023-09-11T10:13:17.004150Z","shell.execute_reply":"2023-09-11T10:13:17.002551Z","shell.execute_reply.started":"2023-09-11T10:13:16.988275Z"},"trusted":true},"outputs":[],"source":["class Transformer(nn.Module):\n","    def __init__(\n","        self,\n","        dim,\n","        num_heads,\n","        depth,\n","        mask=None\n","    ):\n","        super().__init__()\n","        self.resblocks = nn.Sequential(*[\n","            ResidualAttentionBlock(\n","                dim=dim,\n","                num_heads=num_heads,\n","                mask=mask\n","            ) for _ in range(depth)\n","        ])\n","        \n","    def forward(self, x):\n","        return self.resblocks(x)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-09-11T10:13:17.007354Z","iopub.status.busy":"2023-09-11T10:13:17.005725Z","iopub.status.idle":"2023-09-11T10:13:17.023037Z","shell.execute_reply":"2023-09-11T10:13:17.021573Z","shell.execute_reply.started":"2023-09-11T10:13:17.007273Z"},"trusted":true},"outputs":[],"source":["class VisionTransformer(nn.Module):\n","    def __init__(\n","        self,\n","        img_size,\n","        patch_size,\n","        dim,\n","        num_heads,\n","        depth,\n","        out_dim\n","    ):\n","        super().__init__()\n","        \n","        num_patches = (img_size // patch_size)** 2\n","        \n","        self.conv1 = nn.Conv2d(3,dim,patch_size,patch_size,bias=False)\n","        self.ln_pre = nn.LayerNorm(dim)\n","        \n","        self.transformer = Transformer(\n","            dim=dim,\n","            num_heads=num_heads,\n","            depth=depth\n","        )\n","        \n","        self.ln_post = nn.LayerNorm(dim)\n","        \n","        self.class_embedding = nn.Parameter(torch.randn(dim))\n","        self.positional_embedding = nn.Parameter(torch.randn(num_patches+1,dim))\n","        \n","        self.proj = nn.Parameter(torch.randn(dim,out_dim))\n","        \n","    def forward(self, x):\n","        \n","        x = self.conv1(x) # batch x dim x patch_num_cols x patch_num_rows\n","        x = x.reshape(x.size(0),x.size(1),-1) # batch x dim x num_patches\n","        x = x.permute(0,2,1) # batch x num_patches x dim\n","        \n","        # batch x 1 x dim\n","        cls_dim = torch.zeros((x.size(0),1,x.size(2)),dtype=x.dtype)\n","        \n","        # batch x 1 x dim\n","        emb = self.class_embedding + cls_dim\n","        \n","        # batch x num_patches + 1 x dim ; + 1 for [CLS]\n","        x = torch.cat([emb,x],dim=1)\n","        x += self.positional_embedding\n","        \n","        x = self.ln_pre(x)\n","        x = self.transformer(x)\n","        \n","        cls_out = x[:,0,:] # batch x dim\n","        \n","        out = self.ln_post(cls_out)\n","        out = out @ self.proj # batch x dim\n","        \n","        return out"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-09-11T10:13:17.025642Z","iopub.status.busy":"2023-09-11T10:13:17.024816Z","iopub.status.idle":"2023-09-11T10:13:17.043044Z","shell.execute_reply":"2023-09-11T10:13:17.041722Z","shell.execute_reply.started":"2023-09-11T10:13:17.025591Z"},"trusted":true},"outputs":[],"source":["class CLIP(nn.Module):\n","    def __init__(self,config):\n","        \n","        super().__init__()\n","        \n","        self.config = config\n","        \n","        self.vocab_size = self.config['vocab_size']\n","        self.context_length = self.config['context_length']\n","        \n","        self.visual = VisionTransformer(\n","            img_size=self.config['img_size'],\n","            patch_size=self.config['patch_size'],\n","            dim=self.config['vis_dim'],\n","            depth=self.config['depth'],\n","            num_heads=self.config['vis_num_heads'],\n","            out_dim=self.config['out_dim'],\n","        )\n","        \n","        self.transformer = Transformer(\n","            dim=self.config['text_dim'],\n","            num_heads=self.config['text_num_heads'],\n","            depth=self.config['depth'],\n","            mask=torch.tril(torch.ones(1,1,self.context_length,self.context_length))\n","        )\n","        \n","        self.token_embedding = nn.Embedding(self.vocab_size,self.config['text_dim'])\n","        self.positional_embedding = nn.Parameter(torch.rand(self.context_length,self.config['text_dim']))\n","        \n","        self.ln_final = nn.LayerNorm(self.config['text_dim'])\n","        \n","        self.text_projection = nn.Parameter(torch.rand(self.config['text_dim'], self.config['out_dim']))\n","        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / 0.07))\n","        \n","        \n","    def encode_image(self,x):\n","        x = self.visual(x)\n","        return x\n","    \n","    def encode_text(self, text):\n","        x = self.token_embedding(text)\n","        x = x + self.positional_embedding\n","        x = self.transformer(x)\n","        x = self.ln_final(x)\n","\n","        # x.shape = [batch_size, n_ctx, transformer.width]\n","        # take features from the eot embedding (eot_token is the highest number in each sequence)\n","        x = x[torch.arange(x.shape[0]), text.argmax(dim=-1)] @ self.text_projection\n","\n","        return x\n","    \n","    def forward(self, image, text):\n","        image_features = self.encode_image(image)\n","        text_features = self.encode_text(text)\n","\n","        # normalized features\n","        image_features = image_features / image_features.norm(dim=1, keepdim=True)\n","        text_features = text_features / text_features.norm(dim=1, keepdim=True)\n","\n","        # cosine similarity as logits\n","        logit_scale = self.logit_scale.exp()\n","        logits_per_image = logit_scale * image_features @ text_features.t()\n","        logits_per_text = logits_per_image.t()\n","\n","        # shape = [global_batch_size, global_batch_size]\n","        return logits_per_image, logits_per_text"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-09-11T10:13:17.045825Z","iopub.status.busy":"2023-09-11T10:13:17.044926Z","iopub.status.idle":"2023-09-11T10:13:17.062051Z","shell.execute_reply":"2023-09-11T10:13:17.060600Z","shell.execute_reply.started":"2023-09-11T10:13:17.045766Z"},"trusted":true},"outputs":[],"source":["config = {\n","    'img_size': 224,\n","    'patch_size': 32,\n","    'vis_num_heads': 12,\n","    'depth': 12,\n","    'vis_dim': 768,\n","    'out_dim': 512,\n","    'vocab_size': 49408,\n","    'context_length': 77,\n","    'text_dim': 512,\n","    'text_num_heads':8\n","}"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-09-11T10:13:17.064554Z","iopub.status.busy":"2023-09-11T10:13:17.064056Z","iopub.status.idle":"2023-09-11T10:13:18.680883Z","shell.execute_reply":"2023-09-11T10:13:18.679195Z","shell.execute_reply.started":"2023-09-11T10:13:17.064507Z"},"trusted":true},"outputs":[],"source":["cl = CLIP(config)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-09-11T10:13:18.686579Z","iopub.status.busy":"2023-09-11T10:13:18.686145Z","iopub.status.idle":"2023-09-11T10:13:18.698978Z","shell.execute_reply":"2023-09-11T10:13:18.697620Z","shell.execute_reply.started":"2023-09-11T10:13:18.686540Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(torch.Size([2, 3, 224, 224]), torch.Size([2, 77]))"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["img = torch.rand(2,3,224,224)\n","text = clip.tokenize(['a cat','a bat'])\n","img.shape,text.shape"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-09-11T10:13:18.701351Z","iopub.status.busy":"2023-09-11T10:13:18.700242Z","iopub.status.idle":"2023-09-11T10:13:19.084776Z","shell.execute_reply":"2023-09-11T10:13:19.083853Z","shell.execute_reply.started":"2023-09-11T10:13:18.701291Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(tensor([[0.0340, 0.4869],\n","         [0.9051, 1.0849]], grad_fn=<MmBackward0>),\n"," tensor([[0.0340, 0.9051],\n","         [0.4869, 1.0849]], grad_fn=<TBackward0>))"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["cl(img,text)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-09-11T10:13:19.086983Z","iopub.status.busy":"2023-09-11T10:13:19.086321Z","iopub.status.idle":"2023-09-11T10:13:19.091899Z","shell.execute_reply":"2023-09-11T10:13:19.091052Z","shell.execute_reply.started":"2023-09-11T10:13:19.086925Z"},"trusted":true},"outputs":[],"source":["def params(m):\n","    return sum([p.numel() for p in m.parameters() if p.requires_grad])"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-09-11T10:13:19.094099Z","iopub.status.busy":"2023-09-11T10:13:19.093454Z","iopub.status.idle":"2023-09-11T10:13:19.110835Z","shell.execute_reply":"2023-09-11T10:13:19.109780Z","shell.execute_reply.started":"2023-09-11T10:13:19.094066Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(151277313, 151277313)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["params(cl),params(model)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-09-11T10:19:17.568472Z","iopub.status.busy":"2023-09-11T10:19:17.567571Z","iopub.status.idle":"2023-09-11T10:19:17.575994Z","shell.execute_reply":"2023-09-11T10:19:17.574876Z","shell.execute_reply.started":"2023-09-11T10:19:17.568397Z"},"trusted":true},"outputs":[],"source":["def copy_keys(mysd,ogsd):\n","    mykeys = mysd.keys()\n","    ogkeys = ogsd.keys()\n","    \n","    for k1,k2 in list(zip(mykeys,ogkeys)):\n","        assert mysd[k1].shape == ogsd[k2].shape, 'shape mismatch'\n","        mysd[k1].copy_(ogsd[k2])\n","        \n","    return mysd"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-09-11T10:19:48.615743Z","iopub.status.busy":"2023-09-11T10:19:48.615290Z","iopub.status.idle":"2023-09-11T10:19:48.711682Z","shell.execute_reply":"2023-09-11T10:19:48.710699Z","shell.execute_reply.started":"2023-09-11T10:19:48.615706Z"},"trusted":true},"outputs":[],"source":["copied_sd = copy_keys(cl.state_dict(),model.state_dict())"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-09-11T10:20:00.795976Z","iopub.status.busy":"2023-09-11T10:20:00.795572Z","iopub.status.idle":"2023-09-11T10:20:00.815300Z","shell.execute_reply":"2023-09-11T10:20:00.814104Z","shell.execute_reply.started":"2023-09-11T10:20:00.795945Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["cl.load_state_dict(copied_sd)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-09-11T10:20:04.135853Z","iopub.status.busy":"2023-09-11T10:20:04.135380Z","iopub.status.idle":"2023-09-11T10:20:04.148462Z","shell.execute_reply":"2023-09-11T10:20:04.147522Z","shell.execute_reply.started":"2023-09-11T10:20:04.135816Z"},"trusted":true},"outputs":[{"data":{"text/plain":["CLIP(\n","  (visual): VisionTransformer(\n","    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n","    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    (transformer): Transformer(\n","      (resblocks): Sequential(\n","        (0): ResidualAttentionBlock(\n","          (attn): MultiheadAttention(\n","            (in_proj): Linear(in_features=768, out_features=2304, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (mlp): Sequential(\n","            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n","            (gelu): GELU(approximate='none')\n","            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): ResidualAttentionBlock(\n","          (attn): MultiheadAttention(\n","            (in_proj): Linear(in_features=768, out_features=2304, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (mlp): Sequential(\n","            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n","            (gelu): GELU(approximate='none')\n","            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): ResidualAttentionBlock(\n","          (attn): MultiheadAttention(\n","            (in_proj): Linear(in_features=768, out_features=2304, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (mlp): Sequential(\n","            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n","            (gelu): GELU(approximate='none')\n","            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): ResidualAttentionBlock(\n","          (attn): MultiheadAttention(\n","            (in_proj): Linear(in_features=768, out_features=2304, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (mlp): Sequential(\n","            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n","            (gelu): GELU(approximate='none')\n","            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): ResidualAttentionBlock(\n","          (attn): MultiheadAttention(\n","            (in_proj): Linear(in_features=768, out_features=2304, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (mlp): Sequential(\n","            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n","            (gelu): GELU(approximate='none')\n","            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): ResidualAttentionBlock(\n","          (attn): MultiheadAttention(\n","            (in_proj): Linear(in_features=768, out_features=2304, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (mlp): Sequential(\n","            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n","            (gelu): GELU(approximate='none')\n","            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (6): ResidualAttentionBlock(\n","          (attn): MultiheadAttention(\n","            (in_proj): Linear(in_features=768, out_features=2304, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (mlp): Sequential(\n","            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n","            (gelu): GELU(approximate='none')\n","            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (7): ResidualAttentionBlock(\n","          (attn): MultiheadAttention(\n","            (in_proj): Linear(in_features=768, out_features=2304, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (mlp): Sequential(\n","            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n","            (gelu): GELU(approximate='none')\n","            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (8): ResidualAttentionBlock(\n","          (attn): MultiheadAttention(\n","            (in_proj): Linear(in_features=768, out_features=2304, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (mlp): Sequential(\n","            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n","            (gelu): GELU(approximate='none')\n","            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (9): ResidualAttentionBlock(\n","          (attn): MultiheadAttention(\n","            (in_proj): Linear(in_features=768, out_features=2304, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (mlp): Sequential(\n","            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n","            (gelu): GELU(approximate='none')\n","            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (10): ResidualAttentionBlock(\n","          (attn): MultiheadAttention(\n","            (in_proj): Linear(in_features=768, out_features=2304, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (mlp): Sequential(\n","            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n","            (gelu): GELU(approximate='none')\n","            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (11): ResidualAttentionBlock(\n","          (attn): MultiheadAttention(\n","            (in_proj): Linear(in_features=768, out_features=2304, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (mlp): Sequential(\n","            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n","            (gelu): GELU(approximate='none')\n","            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (transformer): Transformer(\n","    (resblocks): Sequential(\n","      (0): ResidualAttentionBlock(\n","        (attn): MultiheadAttention(\n","          (in_proj): Linear(in_features=512, out_features=1536, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Sequential(\n","          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n","          (gelu): GELU(approximate='none')\n","          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): ResidualAttentionBlock(\n","        (attn): MultiheadAttention(\n","          (in_proj): Linear(in_features=512, out_features=1536, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Sequential(\n","          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n","          (gelu): GELU(approximate='none')\n","          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): ResidualAttentionBlock(\n","        (attn): MultiheadAttention(\n","          (in_proj): Linear(in_features=512, out_features=1536, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Sequential(\n","          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n","          (gelu): GELU(approximate='none')\n","          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): ResidualAttentionBlock(\n","        (attn): MultiheadAttention(\n","          (in_proj): Linear(in_features=512, out_features=1536, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Sequential(\n","          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n","          (gelu): GELU(approximate='none')\n","          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (4): ResidualAttentionBlock(\n","        (attn): MultiheadAttention(\n","          (in_proj): Linear(in_features=512, out_features=1536, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Sequential(\n","          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n","          (gelu): GELU(approximate='none')\n","          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (5): ResidualAttentionBlock(\n","        (attn): MultiheadAttention(\n","          (in_proj): Linear(in_features=512, out_features=1536, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Sequential(\n","          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n","          (gelu): GELU(approximate='none')\n","          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (6): ResidualAttentionBlock(\n","        (attn): MultiheadAttention(\n","          (in_proj): Linear(in_features=512, out_features=1536, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Sequential(\n","          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n","          (gelu): GELU(approximate='none')\n","          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (7): ResidualAttentionBlock(\n","        (attn): MultiheadAttention(\n","          (in_proj): Linear(in_features=512, out_features=1536, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Sequential(\n","          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n","          (gelu): GELU(approximate='none')\n","          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (8): ResidualAttentionBlock(\n","        (attn): MultiheadAttention(\n","          (in_proj): Linear(in_features=512, out_features=1536, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Sequential(\n","          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n","          (gelu): GELU(approximate='none')\n","          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (9): ResidualAttentionBlock(\n","        (attn): MultiheadAttention(\n","          (in_proj): Linear(in_features=512, out_features=1536, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Sequential(\n","          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n","          (gelu): GELU(approximate='none')\n","          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (10): ResidualAttentionBlock(\n","        (attn): MultiheadAttention(\n","          (in_proj): Linear(in_features=512, out_features=1536, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Sequential(\n","          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n","          (gelu): GELU(approximate='none')\n","          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (11): ResidualAttentionBlock(\n","        (attn): MultiheadAttention(\n","          (in_proj): Linear(in_features=512, out_features=1536, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (mlp): Sequential(\n","          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n","          (gelu): GELU(approximate='none')\n","          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n","        )\n","        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  (token_embedding): Embedding(49408, 512)\n","  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",")"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["cl"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
