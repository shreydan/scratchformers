{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install einops -q","metadata":{"execution":{"iopub.status.busy":"2023-08-09T18:48:08.594683Z","iopub.execute_input":"2023-08-09T18:48:08.595082Z","iopub.status.idle":"2023-08-09T18:48:08.600220Z","shell.execute_reply.started":"2023-08-09T18:48:08.595053Z","shell.execute_reply":"2023-08-09T18:48:08.598882Z"},"trusted":true},"execution_count":177,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\nfrom types import SimpleNamespace\nfrom einops import rearrange\nimport torch.nn.functional as F","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-09T18:48:08.606128Z","iopub.execute_input":"2023-08-09T18:48:08.606498Z","iopub.status.idle":"2023-08-09T18:48:08.613497Z","shell.execute_reply.started":"2023-08-09T18:48:08.606467Z","shell.execute_reply":"2023-08-09T18:48:08.612440Z"},"trusted":true},"execution_count":178,"outputs":[]},{"cell_type":"code","source":"gpt2 = GPT2LMHeadModel.from_pretrained('gpt2')","metadata":{"execution":{"iopub.status.busy":"2023-08-09T18:48:08.618960Z","iopub.execute_input":"2023-08-09T18:48:08.619354Z","iopub.status.idle":"2023-08-09T18:48:11.136830Z","shell.execute_reply.started":"2023-08-09T18:48:08.619323Z","shell.execute_reply":"2023-08-09T18:48:11.135543Z"},"trusted":true},"execution_count":179,"outputs":[]},{"cell_type":"code","source":"gpt2","metadata":{"execution":{"iopub.status.busy":"2023-08-09T18:48:11.138985Z","iopub.execute_input":"2023-08-09T18:48:11.139413Z","iopub.status.idle":"2023-08-09T18:48:11.147170Z","shell.execute_reply.started":"2023-08-09T18:48:11.139382Z","shell.execute_reply":"2023-08-09T18:48:11.145996Z"},"trusted":true},"execution_count":180,"outputs":[{"execution_count":180,"output_type":"execute_result","data":{"text/plain":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"sd = gpt2.state_dict()\n\nprint('transformer')\nfor key in sd.keys():\n    if 'transformer' in key:\n        print('\\t',key.replace('transformer.',''))\n    else:\n        print(key)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T18:48:11.148445Z","iopub.execute_input":"2023-08-09T18:48:11.148992Z","iopub.status.idle":"2023-08-09T18:48:11.162223Z","shell.execute_reply.started":"2023-08-09T18:48:11.148950Z","shell.execute_reply":"2023-08-09T18:48:11.161146Z"},"trusted":true},"execution_count":181,"outputs":[{"name":"stdout","text":"transformer\n\t wte.weight\n\t wpe.weight\n\t h.0.ln_1.weight\n\t h.0.ln_1.bias\n\t h.0.attn.c_attn.weight\n\t h.0.attn.c_attn.bias\n\t h.0.attn.c_proj.weight\n\t h.0.attn.c_proj.bias\n\t h.0.ln_2.weight\n\t h.0.ln_2.bias\n\t h.0.mlp.c_fc.weight\n\t h.0.mlp.c_fc.bias\n\t h.0.mlp.c_proj.weight\n\t h.0.mlp.c_proj.bias\n\t h.1.ln_1.weight\n\t h.1.ln_1.bias\n\t h.1.attn.c_attn.weight\n\t h.1.attn.c_attn.bias\n\t h.1.attn.c_proj.weight\n\t h.1.attn.c_proj.bias\n\t h.1.ln_2.weight\n\t h.1.ln_2.bias\n\t h.1.mlp.c_fc.weight\n\t h.1.mlp.c_fc.bias\n\t h.1.mlp.c_proj.weight\n\t h.1.mlp.c_proj.bias\n\t h.2.ln_1.weight\n\t h.2.ln_1.bias\n\t h.2.attn.c_attn.weight\n\t h.2.attn.c_attn.bias\n\t h.2.attn.c_proj.weight\n\t h.2.attn.c_proj.bias\n\t h.2.ln_2.weight\n\t h.2.ln_2.bias\n\t h.2.mlp.c_fc.weight\n\t h.2.mlp.c_fc.bias\n\t h.2.mlp.c_proj.weight\n\t h.2.mlp.c_proj.bias\n\t h.3.ln_1.weight\n\t h.3.ln_1.bias\n\t h.3.attn.c_attn.weight\n\t h.3.attn.c_attn.bias\n\t h.3.attn.c_proj.weight\n\t h.3.attn.c_proj.bias\n\t h.3.ln_2.weight\n\t h.3.ln_2.bias\n\t h.3.mlp.c_fc.weight\n\t h.3.mlp.c_fc.bias\n\t h.3.mlp.c_proj.weight\n\t h.3.mlp.c_proj.bias\n\t h.4.ln_1.weight\n\t h.4.ln_1.bias\n\t h.4.attn.c_attn.weight\n\t h.4.attn.c_attn.bias\n\t h.4.attn.c_proj.weight\n\t h.4.attn.c_proj.bias\n\t h.4.ln_2.weight\n\t h.4.ln_2.bias\n\t h.4.mlp.c_fc.weight\n\t h.4.mlp.c_fc.bias\n\t h.4.mlp.c_proj.weight\n\t h.4.mlp.c_proj.bias\n\t h.5.ln_1.weight\n\t h.5.ln_1.bias\n\t h.5.attn.c_attn.weight\n\t h.5.attn.c_attn.bias\n\t h.5.attn.c_proj.weight\n\t h.5.attn.c_proj.bias\n\t h.5.ln_2.weight\n\t h.5.ln_2.bias\n\t h.5.mlp.c_fc.weight\n\t h.5.mlp.c_fc.bias\n\t h.5.mlp.c_proj.weight\n\t h.5.mlp.c_proj.bias\n\t h.6.ln_1.weight\n\t h.6.ln_1.bias\n\t h.6.attn.c_attn.weight\n\t h.6.attn.c_attn.bias\n\t h.6.attn.c_proj.weight\n\t h.6.attn.c_proj.bias\n\t h.6.ln_2.weight\n\t h.6.ln_2.bias\n\t h.6.mlp.c_fc.weight\n\t h.6.mlp.c_fc.bias\n\t h.6.mlp.c_proj.weight\n\t h.6.mlp.c_proj.bias\n\t h.7.ln_1.weight\n\t h.7.ln_1.bias\n\t h.7.attn.c_attn.weight\n\t h.7.attn.c_attn.bias\n\t h.7.attn.c_proj.weight\n\t h.7.attn.c_proj.bias\n\t h.7.ln_2.weight\n\t h.7.ln_2.bias\n\t h.7.mlp.c_fc.weight\n\t h.7.mlp.c_fc.bias\n\t h.7.mlp.c_proj.weight\n\t h.7.mlp.c_proj.bias\n\t h.8.ln_1.weight\n\t h.8.ln_1.bias\n\t h.8.attn.c_attn.weight\n\t h.8.attn.c_attn.bias\n\t h.8.attn.c_proj.weight\n\t h.8.attn.c_proj.bias\n\t h.8.ln_2.weight\n\t h.8.ln_2.bias\n\t h.8.mlp.c_fc.weight\n\t h.8.mlp.c_fc.bias\n\t h.8.mlp.c_proj.weight\n\t h.8.mlp.c_proj.bias\n\t h.9.ln_1.weight\n\t h.9.ln_1.bias\n\t h.9.attn.c_attn.weight\n\t h.9.attn.c_attn.bias\n\t h.9.attn.c_proj.weight\n\t h.9.attn.c_proj.bias\n\t h.9.ln_2.weight\n\t h.9.ln_2.bias\n\t h.9.mlp.c_fc.weight\n\t h.9.mlp.c_fc.bias\n\t h.9.mlp.c_proj.weight\n\t h.9.mlp.c_proj.bias\n\t h.10.ln_1.weight\n\t h.10.ln_1.bias\n\t h.10.attn.c_attn.weight\n\t h.10.attn.c_attn.bias\n\t h.10.attn.c_proj.weight\n\t h.10.attn.c_proj.bias\n\t h.10.ln_2.weight\n\t h.10.ln_2.bias\n\t h.10.mlp.c_fc.weight\n\t h.10.mlp.c_fc.bias\n\t h.10.mlp.c_proj.weight\n\t h.10.mlp.c_proj.bias\n\t h.11.ln_1.weight\n\t h.11.ln_1.bias\n\t h.11.attn.c_attn.weight\n\t h.11.attn.c_attn.bias\n\t h.11.attn.c_proj.weight\n\t h.11.attn.c_proj.bias\n\t h.11.ln_2.weight\n\t h.11.ln_2.bias\n\t h.11.mlp.c_fc.weight\n\t h.11.mlp.c_fc.bias\n\t h.11.mlp.c_proj.weight\n\t h.11.mlp.c_proj.bias\n\t ln_f.weight\n\t ln_f.bias\nlm_head.weight\n","output_type":"stream"}]},{"cell_type":"code","source":"gpt2.transformer.h[0]","metadata":{"execution":{"iopub.status.busy":"2023-08-09T18:48:11.165984Z","iopub.execute_input":"2023-08-09T18:48:11.166396Z","iopub.status.idle":"2023-08-09T18:48:11.175931Z","shell.execute_reply.started":"2023-08-09T18:48:11.166363Z","shell.execute_reply":"2023-08-09T18:48:11.174696Z"},"trusted":true},"execution_count":182,"outputs":[{"execution_count":182,"output_type":"execute_result","data":{"text/plain":"GPT2Block(\n  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  (attn): GPT2Attention(\n    (c_attn): Conv1D()\n    (c_proj): Conv1D()\n    (attn_dropout): Dropout(p=0.1, inplace=False)\n    (resid_dropout): Dropout(p=0.1, inplace=False)\n  )\n  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  (mlp): GPT2MLP(\n    (c_fc): Conv1D()\n    (c_proj): Conv1D()\n    (act): NewGELUActivation()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"gpt2.transformer.h[0].mlp.state_dict().keys()","metadata":{"execution":{"iopub.status.busy":"2023-08-09T18:48:11.178793Z","iopub.execute_input":"2023-08-09T18:48:11.179308Z","iopub.status.idle":"2023-08-09T18:48:11.187837Z","shell.execute_reply.started":"2023-08-09T18:48:11.179266Z","shell.execute_reply":"2023-08-09T18:48:11.186786Z"},"trusted":true},"execution_count":183,"outputs":[{"execution_count":183,"output_type":"execute_result","data":{"text/plain":"odict_keys(['c_fc.weight', 'c_fc.bias', 'c_proj.weight', 'c_proj.bias'])"},"metadata":{}}]},{"cell_type":"code","source":"gpt2.transformer.h[0].ln_1.state_dict().keys()","metadata":{"execution":{"iopub.status.busy":"2023-08-09T18:48:11.189291Z","iopub.execute_input":"2023-08-09T18:48:11.189651Z","iopub.status.idle":"2023-08-09T18:48:11.198351Z","shell.execute_reply.started":"2023-08-09T18:48:11.189617Z","shell.execute_reply":"2023-08-09T18:48:11.197346Z"},"trusted":true},"execution_count":184,"outputs":[{"execution_count":184,"output_type":"execute_result","data":{"text/plain":"odict_keys(['weight', 'bias'])"},"metadata":{}}]},{"cell_type":"code","source":"gpt2.transformer.wpe","metadata":{"execution":{"iopub.status.busy":"2023-08-09T18:48:11.199383Z","iopub.execute_input":"2023-08-09T18:48:11.199741Z","iopub.status.idle":"2023-08-09T18:48:11.210062Z","shell.execute_reply.started":"2023-08-09T18:48:11.199707Z","shell.execute_reply":"2023-08-09T18:48:11.209152Z"},"trusted":true},"execution_count":185,"outputs":[{"execution_count":185,"output_type":"execute_result","data":{"text/plain":"Embedding(1024, 768)"},"metadata":{}}]},{"cell_type":"code","source":"def params(m):\n    return sum([p.numel() for p in m.parameters()])","metadata":{"execution":{"iopub.status.busy":"2023-08-09T18:48:11.211447Z","iopub.execute_input":"2023-08-09T18:48:11.211889Z","iopub.status.idle":"2023-08-09T18:48:11.218703Z","shell.execute_reply.started":"2023-08-09T18:48:11.211852Z","shell.execute_reply":"2023-08-09T18:48:11.217965Z"},"trusted":true},"execution_count":186,"outputs":[]},{"cell_type":"code","source":"params(gpt2)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T18:48:11.219862Z","iopub.execute_input":"2023-08-09T18:48:11.220275Z","iopub.status.idle":"2023-08-09T18:48:11.232868Z","shell.execute_reply.started":"2023-08-09T18:48:11.220238Z","shell.execute_reply":"2023-08-09T18:48:11.231691Z"},"trusted":true},"execution_count":187,"outputs":[{"execution_count":187,"output_type":"execute_result","data":{"text/plain":"124439808"},"metadata":{}}]},{"cell_type":"code","source":"class GPT2Attention(nn.Module):\n    def __init__(self,config):\n        super().__init__()\n        self.embed_dim = config.embed_dim\n        self.n_heads = config.num_heads\n        assert self.embed_dim % self.n_heads == 0, 'embedding dimension by be divisible by number of heads'\n        self.head_size = self.embed_dim // self.n_heads\n        self.seq_len = config.seq_len\n        \n        self.c_attn = nn.Linear(self.embed_dim, self.head_size * self.n_heads * 3,bias=True)\n        self.scale = self.head_size ** -0.5\n        \n        self.register_buffer('mask',torch.tril(torch.ones(1,1,self.seq_len,self.seq_len)))\n        \n        self.c_proj = nn.Linear(self.embed_dim, self.embed_dim, bias=True)\n        \n        self.attn_dropout = nn.Dropout(config.attention_dropout)\n        self.resid_dropout = nn.Dropout(config.residual_dropout)\n        \n        \n    def forward(self, x):\n        b,t,c = x.shape\n        # q,k,v shape individually: batch_size x seq_len x embed_dim\n        # we know that qk_t = q x k_t, where q=bxtxhead_dim, k_t=bxhead_timxt\n        q,k,v = self.c_attn(x).chunk(3,dim=-1)\n        q = rearrange(q,'b t (h n) -> b n t h',n=self.n_heads) # h = head_size\n        k = rearrange(k,'b t (h n) -> b n t h',n=self.n_heads)\n        v = rearrange(v,'b t (h n) -> b n t h',n=self.n_heads)\n        \n        # qk_t = einsum(q,k,'b n t1 h, b n t2 h -> b n t1 t2') * self.scale\n        qk_t = (q@k.transpose(-2,-1)) * self.scale\n        # fun fact, limit mask to [:,:,:t,:t] else short prompts will not work\n        qk_t = qk_t.masked_fill(self.mask[:,:,:t,:t]==0,float('-inf'))\n        qk_t = F.softmax(qk_t,dim=-1)\n        \n        weights = self.attn_dropout(qk_t)\n        \n        attention = weights @ v # batch x n_heads x seq_len x head_size\n        attention = rearrange(attention,'b n t h -> b t (n h)') # batch x n_heads x seq_len x embed_dim\n        \n        out = self.c_proj(attention)\n        out = self.resid_dropout(out)\n        \n        return out\n    \n\nclass GPT2MLP(nn.Module):\n    def __init__(self,config):\n        super().__init__()\n        self.embed_dim = config.embed_dim\n        self.mlp_ratio = config.mlp_ratio\n        self.mlp_dropout = config.mlp_dropout\n        \n        self.c_fc = nn.Linear(self.embed_dim,self.embed_dim*self.mlp_ratio)\n        self.c_proj = nn.Linear(self.embed_dim*self.mlp_ratio,self.embed_dim)\n        self.act = nn.GELU()\n        self.dropout = nn.Dropout(self.mlp_dropout)\n        \n    def forward(self,x):\n        x = self.c_fc(x)\n        x = self.act(x)\n        x = self.c_proj(x)\n        x = self.dropout(x)\n        return x\n    \n\nclass GPT2Block(nn.Module):\n    def __init__(self,config):\n        super().__init__()\n        self.embed_dim = config.embed_dim\n        self.ln_1 = nn.LayerNorm(self.embed_dim)\n        self.attn = GPT2Attention(config)\n        self.ln_2 = nn.LayerNorm(self.embed_dim)\n        self.mlp = GPT2MLP(config)\n        \n    def forward(self,x):\n        x = x+self.attn(self.ln_1(x))\n        x = x+self.mlp(self.ln_2(x))\n        return x\n    \n\nclass GPT2Model(nn.Module):\n    def __init__(self,config):\n        super().__init__()\n        \n        self.config = config\n        \n        self.transformer = nn.ModuleDict(dict(\n            wte = nn.Embedding(config.vocab_size,config.embed_dim),\n            wpe = nn.Embedding(config.seq_len,config.embed_dim),\n            drop = nn.Dropout(config.emb_dropout),\n            h = nn.ModuleList([GPT2Block(config) for _ in range(config.depth)]),\n            ln_f = nn.LayerNorm(config.embed_dim)\n        ))\n        self.lm_head = nn.Linear(config.embed_dim,config.vocab_size,bias=False)\n        self.transformer.wte.weight = self.lm_head.weight\n        \n    def forward(self,x):\n        b,t = x.shape\n        token_embeddings = self.transformer.wte(x) # batch x seq_len\n        pos_embs = torch.arange(0,x.size(1)).to(x.device)\n        positional_embeddings = self.transformer.wpe(pos_embs)\n        x = self.transformer.drop(token_embeddings+positional_embeddings)\n        for h in self.transformer.h:\n            x = h(x) # batch_size x seq_len x embed_dim\n        x = self.transformer.ln_f(x)[:,[-1],:] # get last hidden state: batch_size x 1 x embed_dim\n        x = self.lm_head(x) # batch_size x vocab_size\n        \n        return x\n    \n    @torch.no_grad()\n    def generate(self,idx,max_new_tokens=5,temperature=1.0):\n        \n        for _ in range(max_new_tokens):\n            \n            inp = idx if idx.size(1) <= self.config.seq_len else inp[:,-self.config.seq_len:]\n            out = self(inp)\n            out = out[:, -1, :] / temperature\n            probs = F.softmax(out, dim=-1)\n            idx_next = torch.multinomial(probs, num_samples=1)\n            idx = torch.cat((idx, idx_next), dim=1)\n            \n        return idx","metadata":{"execution":{"iopub.status.busy":"2023-08-09T18:48:11.237055Z","iopub.execute_input":"2023-08-09T18:48:11.237479Z","iopub.status.idle":"2023-08-09T18:48:11.263080Z","shell.execute_reply.started":"2023-08-09T18:48:11.237447Z","shell.execute_reply":"2023-08-09T18:48:11.262002Z"},"trusted":true},"execution_count":188,"outputs":[]},{"cell_type":"code","source":"gpt2_small = SimpleNamespace(\n        vocab_size = 50_257,\n        embed_dim = 768,\n        num_heads = 12,\n        seq_len = 1024,\n        depth = 12,\n        attention_dropout = 0.1,\n        residual_dropout = 0.1,\n        mlp_ratio = 4,\n        mlp_dropout = 0.1,\n        emb_dropout = 0.1,\n    )","metadata":{"execution":{"iopub.status.busy":"2023-08-09T18:48:11.264377Z","iopub.execute_input":"2023-08-09T18:48:11.265353Z","iopub.status.idle":"2023-08-09T18:48:11.279491Z","shell.execute_reply.started":"2023-08-09T18:48:11.265318Z","shell.execute_reply":"2023-08-09T18:48:11.278320Z"},"trusted":true},"execution_count":189,"outputs":[]},{"cell_type":"code","source":"mygpt = GPT2Model(gpt2_small)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T18:48:11.281327Z","iopub.execute_input":"2023-08-09T18:48:11.281797Z","iopub.status.idle":"2023-08-09T18:48:13.238186Z","shell.execute_reply.started":"2023-08-09T18:48:11.281684Z","shell.execute_reply":"2023-08-09T18:48:13.237025Z"},"trusted":true},"execution_count":190,"outputs":[]},{"cell_type":"code","source":"params(mygpt), params(gpt2)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T18:48:13.239663Z","iopub.execute_input":"2023-08-09T18:48:13.239994Z","iopub.status.idle":"2023-08-09T18:48:13.248406Z","shell.execute_reply.started":"2023-08-09T18:48:13.239966Z","shell.execute_reply":"2023-08-09T18:48:13.247226Z"},"trusted":true},"execution_count":191,"outputs":[{"execution_count":191,"output_type":"execute_result","data":{"text/plain":"(124439808, 124439808)"},"metadata":{}}]},{"cell_type":"code","source":"my_unique_keys = set(mygpt.state_dict().keys())\ntrained_unique_keys = set(gpt2.state_dict().keys())\nmy_unique_keys - trained_unique_keys","metadata":{"execution":{"iopub.status.busy":"2023-08-09T18:48:13.250083Z","iopub.execute_input":"2023-08-09T18:48:13.250976Z","iopub.status.idle":"2023-08-09T18:48:13.267314Z","shell.execute_reply.started":"2023-08-09T18:48:13.250940Z","shell.execute_reply":"2023-08-09T18:48:13.266142Z"},"trusted":true},"execution_count":192,"outputs":[{"execution_count":192,"output_type":"execute_result","data":{"text/plain":"{'transformer.h.0.attn.mask',\n 'transformer.h.1.attn.mask',\n 'transformer.h.10.attn.mask',\n 'transformer.h.11.attn.mask',\n 'transformer.h.2.attn.mask',\n 'transformer.h.3.attn.mask',\n 'transformer.h.4.attn.mask',\n 'transformer.h.5.attn.mask',\n 'transformer.h.6.attn.mask',\n 'transformer.h.7.attn.mask',\n 'transformer.h.8.attn.mask',\n 'transformer.h.9.attn.mask'}"},"metadata":{}}]},{"cell_type":"code","source":"@torch.no_grad()\ndef copy_state_dict(my_sd, hf_sd):\n    sd_keys_my = [k for k in hf_sd.keys() if not k.endswith('.attn.mask')]\n    sd_keys_hf = hf_sd.keys()\n    sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n    sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n    transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n    \n    len_hf = len(sd_keys_hf)\n    len_my = len(sd_keys_my)\n    \n    assert len_hf == len_my\n    \n    for key in sd_keys_hf:\n        if any(key.endswith(w) for w in transposed):\n            print('transposed',key,my_sd[key].shape,hf_sd[key].shape[::-1])\n            assert my_sd[key].shape == hf_sd[key].shape[::-1]\n            my_sd[key].copy_(hf_sd[key].t())\n        else:\n            print('normal',key,my_sd[key].shape,hf_sd[key].shape)\n            assert my_sd[key].shape == hf_sd[key].shape\n            my_sd[key].copy_(hf_sd[key])\n            \n    return my_sd","metadata":{"execution":{"iopub.status.busy":"2023-08-09T18:48:13.268877Z","iopub.execute_input":"2023-08-09T18:48:13.269238Z","iopub.status.idle":"2023-08-09T18:48:13.278457Z","shell.execute_reply.started":"2023-08-09T18:48:13.269209Z","shell.execute_reply":"2023-08-09T18:48:13.277590Z"},"trusted":true},"execution_count":193,"outputs":[]},{"cell_type":"code","source":"copied_sd = copy_state_dict(mygpt.state_dict(),gpt2.state_dict())","metadata":{"execution":{"iopub.status.busy":"2023-08-09T18:48:13.279510Z","iopub.execute_input":"2023-08-09T18:48:13.279854Z","iopub.status.idle":"2023-08-09T18:48:13.649798Z","shell.execute_reply.started":"2023-08-09T18:48:13.279825Z","shell.execute_reply":"2023-08-09T18:48:13.648734Z"},"trusted":true},"execution_count":194,"outputs":[{"name":"stdout","text":"normal transformer.wte.weight torch.Size([50257, 768]) torch.Size([50257, 768])\nnormal transformer.wpe.weight torch.Size([1024, 768]) torch.Size([1024, 768])\nnormal transformer.h.0.ln_1.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.0.ln_1.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.0.attn.c_attn.weight torch.Size([2304, 768]) torch.Size([2304, 768])\nnormal transformer.h.0.attn.c_attn.bias torch.Size([2304]) torch.Size([2304])\ntransposed transformer.h.0.attn.c_proj.weight torch.Size([768, 768]) torch.Size([768, 768])\nnormal transformer.h.0.attn.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.h.0.ln_2.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.0.ln_2.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.0.mlp.c_fc.weight torch.Size([3072, 768]) torch.Size([3072, 768])\nnormal transformer.h.0.mlp.c_fc.bias torch.Size([3072]) torch.Size([3072])\ntransposed transformer.h.0.mlp.c_proj.weight torch.Size([768, 3072]) torch.Size([768, 3072])\nnormal transformer.h.0.mlp.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.h.1.ln_1.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.1.ln_1.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.1.attn.c_attn.weight torch.Size([2304, 768]) torch.Size([2304, 768])\nnormal transformer.h.1.attn.c_attn.bias torch.Size([2304]) torch.Size([2304])\ntransposed transformer.h.1.attn.c_proj.weight torch.Size([768, 768]) torch.Size([768, 768])\nnormal transformer.h.1.attn.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.h.1.ln_2.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.1.ln_2.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.1.mlp.c_fc.weight torch.Size([3072, 768]) torch.Size([3072, 768])\nnormal transformer.h.1.mlp.c_fc.bias torch.Size([3072]) torch.Size([3072])\ntransposed transformer.h.1.mlp.c_proj.weight torch.Size([768, 3072]) torch.Size([768, 3072])\nnormal transformer.h.1.mlp.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.h.2.ln_1.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.2.ln_1.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.2.attn.c_attn.weight torch.Size([2304, 768]) torch.Size([2304, 768])\nnormal transformer.h.2.attn.c_attn.bias torch.Size([2304]) torch.Size([2304])\ntransposed transformer.h.2.attn.c_proj.weight torch.Size([768, 768]) torch.Size([768, 768])\nnormal transformer.h.2.attn.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.h.2.ln_2.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.2.ln_2.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.2.mlp.c_fc.weight torch.Size([3072, 768]) torch.Size([3072, 768])\nnormal transformer.h.2.mlp.c_fc.bias torch.Size([3072]) torch.Size([3072])\ntransposed transformer.h.2.mlp.c_proj.weight torch.Size([768, 3072]) torch.Size([768, 3072])\nnormal transformer.h.2.mlp.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.h.3.ln_1.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.3.ln_1.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.3.attn.c_attn.weight torch.Size([2304, 768]) torch.Size([2304, 768])\nnormal transformer.h.3.attn.c_attn.bias torch.Size([2304]) torch.Size([2304])\ntransposed transformer.h.3.attn.c_proj.weight torch.Size([768, 768]) torch.Size([768, 768])\nnormal transformer.h.3.attn.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.h.3.ln_2.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.3.ln_2.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.3.mlp.c_fc.weight torch.Size([3072, 768]) torch.Size([3072, 768])\nnormal transformer.h.3.mlp.c_fc.bias torch.Size([3072]) torch.Size([3072])\ntransposed transformer.h.3.mlp.c_proj.weight torch.Size([768, 3072]) torch.Size([768, 3072])\nnormal transformer.h.3.mlp.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.h.4.ln_1.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.4.ln_1.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.4.attn.c_attn.weight torch.Size([2304, 768]) torch.Size([2304, 768])\nnormal transformer.h.4.attn.c_attn.bias torch.Size([2304]) torch.Size([2304])\ntransposed transformer.h.4.attn.c_proj.weight torch.Size([768, 768]) torch.Size([768, 768])\nnormal transformer.h.4.attn.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.h.4.ln_2.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.4.ln_2.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.4.mlp.c_fc.weight torch.Size([3072, 768]) torch.Size([3072, 768])\nnormal transformer.h.4.mlp.c_fc.bias torch.Size([3072]) torch.Size([3072])\ntransposed transformer.h.4.mlp.c_proj.weight torch.Size([768, 3072]) torch.Size([768, 3072])\nnormal transformer.h.4.mlp.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.h.5.ln_1.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.5.ln_1.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.5.attn.c_attn.weight torch.Size([2304, 768]) torch.Size([2304, 768])\nnormal transformer.h.5.attn.c_attn.bias torch.Size([2304]) torch.Size([2304])\ntransposed transformer.h.5.attn.c_proj.weight torch.Size([768, 768]) torch.Size([768, 768])\nnormal transformer.h.5.attn.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.h.5.ln_2.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.5.ln_2.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.5.mlp.c_fc.weight torch.Size([3072, 768]) torch.Size([3072, 768])\nnormal transformer.h.5.mlp.c_fc.bias torch.Size([3072]) torch.Size([3072])\ntransposed transformer.h.5.mlp.c_proj.weight torch.Size([768, 3072]) torch.Size([768, 3072])\nnormal transformer.h.5.mlp.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.h.6.ln_1.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.6.ln_1.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.6.attn.c_attn.weight torch.Size([2304, 768]) torch.Size([2304, 768])\nnormal transformer.h.6.attn.c_attn.bias torch.Size([2304]) torch.Size([2304])\ntransposed transformer.h.6.attn.c_proj.weight torch.Size([768, 768]) torch.Size([768, 768])\nnormal transformer.h.6.attn.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.h.6.ln_2.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.6.ln_2.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.6.mlp.c_fc.weight torch.Size([3072, 768]) torch.Size([3072, 768])\nnormal transformer.h.6.mlp.c_fc.bias torch.Size([3072]) torch.Size([3072])\ntransposed transformer.h.6.mlp.c_proj.weight torch.Size([768, 3072]) torch.Size([768, 3072])\nnormal transformer.h.6.mlp.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.h.7.ln_1.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.7.ln_1.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.7.attn.c_attn.weight torch.Size([2304, 768]) torch.Size([2304, 768])\nnormal transformer.h.7.attn.c_attn.bias torch.Size([2304]) torch.Size([2304])\ntransposed transformer.h.7.attn.c_proj.weight torch.Size([768, 768]) torch.Size([768, 768])\nnormal transformer.h.7.attn.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.h.7.ln_2.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.7.ln_2.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.7.mlp.c_fc.weight torch.Size([3072, 768]) torch.Size([3072, 768])\nnormal transformer.h.7.mlp.c_fc.bias torch.Size([3072]) torch.Size([3072])\ntransposed transformer.h.7.mlp.c_proj.weight torch.Size([768, 3072]) torch.Size([768, 3072])\nnormal transformer.h.7.mlp.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.h.8.ln_1.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.8.ln_1.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.8.attn.c_attn.weight torch.Size([2304, 768]) torch.Size([2304, 768])\nnormal transformer.h.8.attn.c_attn.bias torch.Size([2304]) torch.Size([2304])\ntransposed transformer.h.8.attn.c_proj.weight torch.Size([768, 768]) torch.Size([768, 768])\nnormal transformer.h.8.attn.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.h.8.ln_2.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.8.ln_2.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.8.mlp.c_fc.weight torch.Size([3072, 768]) torch.Size([3072, 768])\nnormal transformer.h.8.mlp.c_fc.bias torch.Size([3072]) torch.Size([3072])\ntransposed transformer.h.8.mlp.c_proj.weight torch.Size([768, 3072]) torch.Size([768, 3072])\nnormal transformer.h.8.mlp.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.h.9.ln_1.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.9.ln_1.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.9.attn.c_attn.weight torch.Size([2304, 768]) torch.Size([2304, 768])\nnormal transformer.h.9.attn.c_attn.bias torch.Size([2304]) torch.Size([2304])\ntransposed transformer.h.9.attn.c_proj.weight torch.Size([768, 768]) torch.Size([768, 768])\nnormal transformer.h.9.attn.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.h.9.ln_2.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.9.ln_2.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.9.mlp.c_fc.weight torch.Size([3072, 768]) torch.Size([3072, 768])\nnormal transformer.h.9.mlp.c_fc.bias torch.Size([3072]) torch.Size([3072])\ntransposed transformer.h.9.mlp.c_proj.weight torch.Size([768, 3072]) torch.Size([768, 3072])\nnormal transformer.h.9.mlp.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.h.10.ln_1.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.10.ln_1.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.10.attn.c_attn.weight torch.Size([2304, 768]) torch.Size([2304, 768])\nnormal transformer.h.10.attn.c_attn.bias torch.Size([2304]) torch.Size([2304])\ntransposed transformer.h.10.attn.c_proj.weight torch.Size([768, 768]) torch.Size([768, 768])\nnormal transformer.h.10.attn.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.h.10.ln_2.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.10.ln_2.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.10.mlp.c_fc.weight torch.Size([3072, 768]) torch.Size([3072, 768])\nnormal transformer.h.10.mlp.c_fc.bias torch.Size([3072]) torch.Size([3072])\ntransposed transformer.h.10.mlp.c_proj.weight torch.Size([768, 3072]) torch.Size([768, 3072])\nnormal transformer.h.10.mlp.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.h.11.ln_1.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.11.ln_1.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.11.attn.c_attn.weight torch.Size([2304, 768]) torch.Size([2304, 768])\nnormal transformer.h.11.attn.c_attn.bias torch.Size([2304]) torch.Size([2304])\ntransposed transformer.h.11.attn.c_proj.weight torch.Size([768, 768]) torch.Size([768, 768])\nnormal transformer.h.11.attn.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.h.11.ln_2.weight torch.Size([768]) torch.Size([768])\nnormal transformer.h.11.ln_2.bias torch.Size([768]) torch.Size([768])\ntransposed transformer.h.11.mlp.c_fc.weight torch.Size([3072, 768]) torch.Size([3072, 768])\nnormal transformer.h.11.mlp.c_fc.bias torch.Size([3072]) torch.Size([3072])\ntransposed transformer.h.11.mlp.c_proj.weight torch.Size([768, 3072]) torch.Size([768, 3072])\nnormal transformer.h.11.mlp.c_proj.bias torch.Size([768]) torch.Size([768])\nnormal transformer.ln_f.weight torch.Size([768]) torch.Size([768])\nnormal transformer.ln_f.bias torch.Size([768]) torch.Size([768])\nnormal lm_head.weight torch.Size([50257, 768]) torch.Size([50257, 768])\n","output_type":"stream"}]},{"cell_type":"code","source":"mygpt.load_state_dict(copied_sd)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T18:48:13.651381Z","iopub.execute_input":"2023-08-09T18:48:13.651734Z","iopub.status.idle":"2023-08-09T18:48:13.662783Z","shell.execute_reply.started":"2023-08-09T18:48:13.651706Z","shell.execute_reply":"2023-08-09T18:48:13.661655Z"},"trusted":true},"execution_count":195,"outputs":[{"execution_count":195,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]}]}